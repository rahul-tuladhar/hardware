2018-05-08 01:11:07 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2018-05-08 01:11:08 INFO  SparkContext:54 - Running Spark version 2.3.0
2018-05-08 01:11:08 INFO  SparkContext:54 - Submitted application: PopularItems
2018-05-08 01:11:08 INFO  SecurityManager:54 - Changing view acls to: root
2018-05-08 01:11:08 INFO  SecurityManager:54 - Changing modify acls to: root
2018-05-08 01:11:08 INFO  SecurityManager:54 - Changing view acls groups to: 
2018-05-08 01:11:08 INFO  SecurityManager:54 - Changing modify acls groups to: 
2018-05-08 01:11:08 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(root); groups with view permissions: Set(); users  with modify permissions: Set(root); groups with modify permissions: Set()
2018-05-08 01:11:08 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 41889.
2018-05-08 01:11:09 INFO  SparkEnv:54 - Registering MapOutputTracker
2018-05-08 01:11:09 INFO  SparkEnv:54 - Registering BlockManagerMaster
2018-05-08 01:11:09 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2018-05-08 01:11:09 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2018-05-08 01:11:09 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-1b3f8ffe-e071-4c99-a461-bf8b446c73ec
2018-05-08 01:11:09 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2018-05-08 01:11:09 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2018-05-08 01:11:09 INFO  log:192 - Logging initialized @3373ms
2018-05-08 01:11:09 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2018-05-08 01:11:09 INFO  Server:414 - Started @3671ms
2018-05-08 01:11:09 INFO  AbstractConnector:278 - Started ServerConnector@1c4d62df{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-08 01:11:09 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4040.
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@656221ba{/jobs,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@24dc08da{/jobs/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@42f7aa70{/jobs/job,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@10c07af2{/jobs/job/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@541e3ae8{/stages,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b45be31{/stages/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@61f10e2c{/stages/stage,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@51abca32{/stages/stage/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@38423e45{/stages/pool,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@65921bf8{/stages/pool/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7880fafe{/storage,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@77f55586{/storage/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5eeced2b{/storage/rdd,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2bd470d5{/storage/rdd/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@54fc285b{/environment,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@9f81e27{/environment/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30442f86{/executors,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@389ea383{/executors/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@d95fa3b{/executors/threadDump,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4455d488{/executors/threadDump/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@557ceb9b{/static,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3e5f44e4{/,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2efd75fd{/api,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@3cdb4db2{/jobs/job/kill,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5bc6f0f6{/stages/stage/kill,null,AVAILABLE,@Spark}
2018-05-08 01:11:09 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://spark-master:4040
2018-05-08 01:11:10 INFO  SparkContext:54 - Added file file:/tmp/data/spark.py at spark://spark-master:41889/files/spark.py with timestamp 1525741870367
2018-05-08 01:11:10 INFO  Utils:54 - Copying /tmp/data/spark.py to /tmp/spark-d905caaf-51d8-4be6-bc92-15e12836c4c3/userFiles-bcaa3644-2493-49c8-b5c9-c0555d8b7a5c/spark.py
2018-05-08 01:11:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://spark-master:7077...
2018-05-08 01:11:10 INFO  TransportClientFactory:267 - Successfully created connection to spark-master/172.17.0.3:7077 after 57 ms (0 ms spent in bootstraps)
2018-05-08 01:11:10 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20180508011110-0003
2018-05-08 01:11:10 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 44601.
2018-05-08 01:11:10 INFO  NettyBlockTransferService:54 - Server created on spark-master:44601
2018-05-08 01:11:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20180508011110-0003/0 on worker-20180508005742-172.17.0.10-8881 (172.17.0.10:8881) with 2 core(s)
2018-05-08 01:11:10 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2018-05-08 01:11:10 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20180508011110-0003/0 on hostPort 172.17.0.10:8881 with 2 core(s), 512.0 MB RAM
2018-05-08 01:11:10 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, spark-master, 44601, None)
2018-05-08 01:11:10 INFO  BlockManagerMasterEndpoint:54 - Registering block manager spark-master:44601 with 366.3 MB RAM, BlockManagerId(driver, spark-master, 44601, None)
2018-05-08 01:11:10 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, spark-master, 44601, None)
2018-05-08 01:11:10 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, spark-master, 44601, None)
2018-05-08 01:11:10 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20180508011110-0003/0 is now RUNNING
2018-05-08 01:11:11 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@278bd012{/metrics/json,null,AVAILABLE,@Spark}
2018-05-08 01:11:11 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2018-05-08 01:11:12 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 326.4 KB, free 366.0 MB)
2018-05-08 01:11:12 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 28.1 KB, free 366.0 MB)
2018-05-08 01:11:12 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on spark-master:44601 (size: 28.1 KB, free: 366.3 MB)
2018-05-08 01:11:12 INFO  SparkContext:54 - Created broadcast 0 from textFile at NativeMethodAccessorImpl.java:0
2018-05-08 01:11:12 INFO  FileInputFormat:247 - Total input paths to process : 1
2018-05-08 01:11:12 INFO  SparkContext:54 - Starting job: collect at /tmp/data/spark.py:33
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Registering RDD 3 (groupByKey at /tmp/data/spark.py:14)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Registering RDD 7 (distinct at /tmp/data/spark.py:23)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Registering RDD 11 (groupByKey at /tmp/data/spark.py:23)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Got job 0 (collect at /tmp/data/spark.py:33) with 2 output partitions
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Final stage: ResultStage 3 (collect at /tmp/data/spark.py:33)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Parents of final stage: List(ShuffleMapStage 2)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Missing parents: List(ShuffleMapStage 2)
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /tmp/data/spark.py:14), which has no missing parents
2018-05-08 01:11:13 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 9.5 KB, free 365.9 MB)
2018-05-08 01:11:13 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.9 KB, free 365.9 MB)
2018-05-08 01:11:13 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on spark-master:44601 (size: 5.9 KB, free: 366.3 MB)
2018-05-08 01:11:13 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2018-05-08 01:11:13 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 0 (PairwiseRDD[3] at groupByKey at /tmp/data/spark.py:14) (first 15 tasks are for partitions Vector(0, 1))
2018-05-08 01:11:13 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2018-05-08 01:11:14 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (172.17.0.10:58770) with ID 0
2018-05-08 01:11:14 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 172.17.0.10:37375 with 93.3 MB RAM, BlockManagerId(0, 172.17.0.10, 37375, None)
2018-05-08 01:11:14 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 172.17.0.10, executor 0, partition 0, PROCESS_LOCAL, 7863 bytes)
2018-05-08 01:11:14 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 172.17.0.10, executor 0, partition 1, PROCESS_LOCAL, 7863 bytes)
2018-05-08 01:11:15 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 172.17.0.10:37375 (size: 5.9 KB, free: 93.3 MB)
2018-05-08 01:11:15 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 172.17.0.10:37375 (size: 28.1 KB, free: 93.3 MB)
2018-05-08 01:11:16 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 2291 ms on 172.17.0.10 (executor 0) (1/2)
2018-05-08 01:11:16 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 2548 ms on 172.17.0.10 (executor 0) (2/2)
2018-05-08 01:11:16 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2018-05-08 01:11:16 INFO  DAGScheduler:54 - ShuffleMapStage 0 (groupByKey at /tmp/data/spark.py:14) finished in 3.763 s
2018-05-08 01:11:16 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-05-08 01:11:16 INFO  DAGScheduler:54 - running: Set()
2018-05-08 01:11:16 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 1, ShuffleMapStage 2, ResultStage 3)
2018-05-08 01:11:16 INFO  DAGScheduler:54 - failed: Set()
2018-05-08 01:11:16 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 1 (PairwiseRDD[7] at distinct at /tmp/data/spark.py:23), which has no missing parents
2018-05-08 01:11:16 INFO  MemoryStore:54 - Block broadcast_2 stored as values in memory (estimated size 10.4 KB, free 365.9 MB)
2018-05-08 01:11:16 INFO  MemoryStore:54 - Block broadcast_2_piece0 stored as bytes in memory (estimated size 6.5 KB, free 365.9 MB)
2018-05-08 01:11:16 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on spark-master:44601 (size: 6.5 KB, free: 366.3 MB)
2018-05-08 01:11:16 INFO  SparkContext:54 - Created broadcast 2 from broadcast at DAGScheduler.scala:1039
2018-05-08 01:11:16 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 1 (PairwiseRDD[7] at distinct at /tmp/data/spark.py:23) (first 15 tasks are for partitions Vector(0, 1))
2018-05-08 01:11:16 INFO  TaskSchedulerImpl:54 - Adding task set 1.0 with 2 tasks
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 1.0 (TID 2, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7642 bytes)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 1.0 (TID 3, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7642 bytes)
2018-05-08 01:11:17 INFO  BlockManagerInfo:54 - Added broadcast_2_piece0 in memory on 172.17.0.10:37375 (size: 6.5 KB, free: 93.3 MB)
2018-05-08 01:11:17 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 2 to 172.17.0.10:58770
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 1.0 (TID 3) in 213 ms on 172.17.0.10 (executor 0) (1/2)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 1.0 (TID 2) in 243 ms on 172.17.0.10 (executor 0) (2/2)
2018-05-08 01:11:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 1.0, whose tasks have all completed, from pool 
2018-05-08 01:11:17 INFO  DAGScheduler:54 - ShuffleMapStage 1 (distinct at /tmp/data/spark.py:23) finished in 0.259 s
2018-05-08 01:11:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-05-08 01:11:17 INFO  DAGScheduler:54 - running: Set()
2018-05-08 01:11:17 INFO  DAGScheduler:54 - waiting: Set(ShuffleMapStage 2, ResultStage 3)
2018-05-08 01:11:17 INFO  DAGScheduler:54 - failed: Set()
2018-05-08 01:11:17 INFO  DAGScheduler:54 - Submitting ShuffleMapStage 2 (PairwiseRDD[11] at groupByKey at /tmp/data/spark.py:23), which has no missing parents
2018-05-08 01:11:17 INFO  MemoryStore:54 - Block broadcast_3 stored as values in memory (estimated size 8.6 KB, free 365.9 MB)
2018-05-08 01:11:17 INFO  MemoryStore:54 - Block broadcast_3_piece0 stored as bytes in memory (estimated size 5.3 KB, free 365.9 MB)
2018-05-08 01:11:17 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on spark-master:44601 (size: 5.3 KB, free: 366.3 MB)
2018-05-08 01:11:17 INFO  SparkContext:54 - Created broadcast 3 from broadcast at DAGScheduler.scala:1039
2018-05-08 01:11:17 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ShuffleMapStage 2 (PairwiseRDD[11] at groupByKey at /tmp/data/spark.py:23) (first 15 tasks are for partitions Vector(0, 1))
2018-05-08 01:11:17 INFO  TaskSchedulerImpl:54 - Adding task set 2.0 with 2 tasks
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 2.0 (TID 4, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7642 bytes)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 2.0 (TID 5, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7642 bytes)
2018-05-08 01:11:17 INFO  BlockManagerInfo:54 - Added broadcast_3_piece0 in memory on 172.17.0.10:37375 (size: 5.3 KB, free: 93.3 MB)
2018-05-08 01:11:17 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 1 to 172.17.0.10:58770
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 2.0 (TID 5) in 161 ms on 172.17.0.10 (executor 0) (1/2)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 2.0 (TID 4) in 170 ms on 172.17.0.10 (executor 0) (2/2)
2018-05-08 01:11:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 2.0, whose tasks have all completed, from pool 
2018-05-08 01:11:17 INFO  DAGScheduler:54 - ShuffleMapStage 2 (groupByKey at /tmp/data/spark.py:23) finished in 0.187 s
2018-05-08 01:11:17 INFO  DAGScheduler:54 - looking for newly runnable stages
2018-05-08 01:11:17 INFO  DAGScheduler:54 - running: Set()
2018-05-08 01:11:17 INFO  DAGScheduler:54 - waiting: Set(ResultStage 3)
2018-05-08 01:11:17 INFO  DAGScheduler:54 - failed: Set()
2018-05-08 01:11:17 INFO  DAGScheduler:54 - Submitting ResultStage 3 (PythonRDD[14] at collect at /tmp/data/spark.py:33), which has no missing parents
2018-05-08 01:11:17 INFO  MemoryStore:54 - Block broadcast_4 stored as values in memory (estimated size 7.6 KB, free 365.9 MB)
2018-05-08 01:11:17 INFO  MemoryStore:54 - Block broadcast_4_piece0 stored as bytes in memory (estimated size 4.6 KB, free 365.9 MB)
2018-05-08 01:11:17 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on spark-master:44601 (size: 4.6 KB, free: 366.3 MB)
2018-05-08 01:11:17 INFO  SparkContext:54 - Created broadcast 4 from broadcast at DAGScheduler.scala:1039
2018-05-08 01:11:17 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 3 (PythonRDD[14] at collect at /tmp/data/spark.py:33) (first 15 tasks are for partitions Vector(0, 1))
2018-05-08 01:11:17 INFO  TaskSchedulerImpl:54 - Adding task set 3.0 with 2 tasks
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 0.0 in stage 3.0 (TID 6, 172.17.0.10, executor 0, partition 0, NODE_LOCAL, 7653 bytes)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Starting task 1.0 in stage 3.0 (TID 7, 172.17.0.10, executor 0, partition 1, NODE_LOCAL, 7653 bytes)
2018-05-08 01:11:17 INFO  BlockManagerInfo:54 - Added broadcast_4_piece0 in memory on 172.17.0.10:37375 (size: 4.6 KB, free: 93.3 MB)
2018-05-08 01:11:17 INFO  MapOutputTrackerMasterEndpoint:54 - Asked to send map output locations for shuffle 0 to 172.17.0.10:58770
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 0.0 in stage 3.0 (TID 6) in 118 ms on 172.17.0.10 (executor 0) (1/2)
2018-05-08 01:11:17 INFO  TaskSetManager:54 - Finished task 1.0 in stage 3.0 (TID 7) in 130 ms on 172.17.0.10 (executor 0) (2/2)
2018-05-08 01:11:17 INFO  TaskSchedulerImpl:54 - Removed TaskSet 3.0, whose tasks have all completed, from pool 
2018-05-08 01:11:17 INFO  DAGScheduler:54 - ResultStage 3 (collect at /tmp/data/spark.py:33) finished in 0.147 s
2018-05-08 01:11:17 INFO  DAGScheduler:54 - Job 0 finished: collect at /tmp/data/spark.py:33, took 4.609143 s
2018-05-08 01:11:17 INFO  AbstractConnector:318 - Stopped Spark@1c4d62df{HTTP/1.1,[http/1.1]}{0.0.0.0:4040}
2018-05-08 01:11:17 INFO  SparkUI:54 - Stopped Spark web UI at http://spark-master:4040
2018-05-08 01:11:17 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2018-05-08 01:11:17 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2018-05-08 01:11:17 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2018-05-08 01:11:17 INFO  MemoryStore:54 - MemoryStore cleared
2018-05-08 01:11:17 INFO  BlockManager:54 - BlockManager stopped
2018-05-08 01:11:17 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2018-05-08 01:11:17 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2018-05-08 01:11:17 INFO  SparkContext:54 - Successfully stopped SparkContext
((1L, '[21, 3, 5, 2]'), (2L, '[3, 21, 1, 5]'), (3L, '[1, 21, 5, 2]'), (5L, '[21, 1, 3, 2]'), (21L, '[1, 3, 5, 2]'))
2018-05-08 01:11:18 INFO  ShutdownHookManager:54 - Shutdown hook called
2018-05-08 01:11:18 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-2131e01e-6bd8-47ec-aa08-19af86e1b69a
2018-05-08 01:11:18 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d905caaf-51d8-4be6-bc92-15e12836c4c3/pyspark-782b54bc-6095-416c-adfb-ea95d8779f1e
2018-05-08 01:11:18 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-d905caaf-51d8-4be6-bc92-15e12836c4c3
